{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Rekognition Object/Scene Detection API\n",
    "Nora Webb Williams | August 15, 2018\n",
    "\n",
    "### Purpose:\n",
    "\n",
    "To demonstrate how to run images through the AWS Rekognition API to do Object/Scene Detection. The resulting csv has a row for each label assigned to each image with greater than 50% confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import boto3 \n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Paths\n",
    "### MUST ADJUST HERE (1/2)\n",
    "# Path to where your want to save the resulting labels\n",
    "rekog_results_dir = 'path_to_where_you_want_to_save_labels'\n",
    "# e.g.:\n",
    "#rekog_results_dir = 'C:/Users/Nora/Desktop/auto_tagger_example/results/'\n",
    "\n",
    "# Path to where your images are\n",
    "rekog_images_dir = 'path_to_where_your_images_are'\n",
    "# e.g.:\n",
    "#rekog_images_dir = 'C:/Users/Nora/Desktop/auto_tagger_example/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Rekognition API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in your personal keys\n",
    "# You can hard code your access key ID and secret key ID into the script, \n",
    "# but this is not recommended\n",
    "\n",
    "personal_access_key = \"your_personal_access_key\"\n",
    "secret_access_key = \"your_secret_access_key\"\n",
    "\n",
    "# Instead we recommend storing your keys securely in a csv or text file.\n",
    "# For example, if you have saved your keys in a csv:\n",
    "\n",
    "credentials = []\n",
    "\n",
    "### MUST ADJUST HERE (2/2)\n",
    "with open('path_to_your_saved_AWS_access_keys.csv', newline='') as csvfile:\n",
    "\n",
    "# e.g.:\n",
    "#with open('C:/Users/Nora/Desktop/auto_tagger_example/keys/AWS_personal_nora_admin_credentials.csv', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        credentials.append(row)\n",
    "\n",
    "personal_access_key = credentials[0]['Access key ID']\n",
    "secret_access_key = credentials[0]['Secret access key']\n",
    "\n",
    "# Initialize the boto client to access the Rekogniton api\n",
    "client=boto3.client('rekognition','us-east-1', # or choose the best region for your work, \n",
    "                                               # e.g. the location of your S3 bucket if using that method to store images\n",
    "                    aws_access_key_id = personal_access_key, \n",
    "                    aws_secret_access_key = secret_access_key) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of images to run through the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make a list of all the images in the rekog_data_dir you created\n",
    "local_images = os.listdir(rekog_images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run each image through the API and store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected labels for ex_1.jpg\n",
      "Coffee Cup : 98.23609924316406\n",
      "Cup : 98.23609924316406\n",
      "Road : 60.62405014038086\n",
      "Freeway : 52.599571228027344\n",
      "Highway : 52.599571228027344\n",
      "Building : 50.51565933227539\n",
      "City : 50.51565933227539\n",
      "Downtown : 50.51565933227539\n",
      "Town : 50.51565933227539\n",
      "Urban : 50.51565933227539\n",
      "Detected labels for ex_2.jpg\n",
      "Human : 99.13925170898438\n",
      "People : 99.13923645019531\n",
      "Person : 99.13925170898438\n",
      "Bar Counter : 98.43019104003906\n",
      "Pub : 98.43019104003906\n",
      "Diner : 97.12300109863281\n",
      "Food : 97.12300109863281\n",
      "Meal : 97.12300109863281\n",
      "Restaurant : 97.12300109863281\n",
      "Worker : 83.39073181152344\n",
      "Animal : 76.40896606445312\n",
      "Aquarium : 76.40896606445312\n",
      "Sea Life : 76.40896606445312\n",
      "Water : 76.40896606445312\n",
      "Lighting : 51.80131149291992\n",
      "Cafe : 50.84360885620117\n",
      "Apparel : 50.51062774658203\n",
      "Clothing : 50.51062774658203\n",
      "Detected labels for ex_3.jpg\n",
      "Brochure : 88.77820587158203\n",
      "Flyer : 88.77820587158203\n",
      "Paper : 88.77820587158203\n",
      "Poster : 88.77820587158203\n",
      "Collage : 56.89072036743164\n",
      "Logo : 54.578433990478516\n",
      "Trademark : 54.578433990478516\n",
      "Text : 53.021060943603516\n",
      "Detected labels for ex_4.jpg\n",
      "Human : 99.23222351074219\n",
      "People : 99.23222351074219\n",
      "Person : 99.23222351074219\n",
      "Audience : 99.06788635253906\n",
      "Crowd : 99.06788635253906\n",
      "Speech : 99.06788635253906\n",
      "Detected labels for ex_5.jpg\n",
      "Human : 99.21126556396484\n",
      "People : 99.21126556396484\n",
      "Person : 99.21126556396484\n",
      "Party : 78.3561782836914\n",
      "Female : 63.80534362792969\n",
      "Face : 60.41244125366211\n",
      "Portrait : 60.41244125366211\n",
      "Smile : 60.41244125366211\n",
      "Laughing : 57.36384582519531\n",
      "Woman : 50.885009765625\n",
      "Crowd : 50.65066909790039\n",
      "Leisure Activities : 50.620906829833984\n",
      "Outdoors : 50.51934051513672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Detect labels\n",
    "## \n",
    "holder_labels = []\n",
    "\n",
    "for imageFile in local_images:\n",
    "    with open(rekog_images_dir + imageFile, 'rb') as image:\n",
    "            response = client.detect_labels(Image={'Bytes': image.read()})\n",
    "    \n",
    "    print('Detected labels for ' + imageFile)\n",
    "    \n",
    "    ## If no labels detected, still save the info:\n",
    "    if len(response['Labels']) == 0:\n",
    "        print (\"No Labels Detected\")\n",
    "        temp_dict = {}\n",
    "        temp_dict[\"image_id\"] = imageFile\n",
    "        temp_dict[\"full_detect_labels_response\"] = response\n",
    "        temp_dict[\"label_num\"] = ''\n",
    "        temp_dict[\"label_str\"] = ''\n",
    "        temp_dict[\"label_conf\"] = ''\n",
    "        temp_dict[\"label_orient_correct\"] = response['OrientationCorrection']\n",
    "        holder_labels.append(temp_dict)   \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        label_counter = 1\n",
    "        \n",
    "        for label in response['Labels']:\n",
    "            print (label['Name'] + ' : ' + str(label['Confidence']))\n",
    "            temp_dict = {}\n",
    "            temp_dict[\"image_id\"] = imageFile\n",
    "            temp_dict[\"full_detect_labels_response\"] = response\n",
    "            temp_dict[\"label_num\"] = label_counter\n",
    "            temp_dict[\"label_str\"] = label['Name']\n",
    "            temp_dict[\"label_conf\"] = label['Confidence']\n",
    "            temp_dict[\"label_orient_correct\"] = response['OrientationCorrection']\n",
    "            label_counter +=1 # update for the next label\n",
    "            holder_labels.append(temp_dict)\n",
    "          \n",
    "len(holder_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out the results to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write out the results to a csv\n",
    "with open(rekog_results_dir + 'awsrekognition_detect_labels.csv', 'w', newline = '') as csvfile:\n",
    "    fieldnames = ['image_id', 'full_detect_labels_response',\n",
    "                  'label_num', 'label_str',\n",
    "                  'label_conf', 'label_orient_correct'\n",
    "                  ]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader() \n",
    "    for entry in holder_labels:\n",
    "        writer.writerow(entry)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3point5]",
   "language": "python",
   "name": "conda-env-python3point5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
